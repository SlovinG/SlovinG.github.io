---
title: Elasticsearch 入门
date: 2020-04-20
tags: 
 - Elasticsearch
 - 分布式
 - 搜索引擎
categories:
 - ES
---

# Elasticsearch 入门

## Elasticsearch 简介

### ES 的作用

Elasticsearch 是一款非常强大的开源搜索引擎，可以帮助我们从海量数据中快速找到需要的内容，一般用来实现搜索、日志统计和分析、系统监控等功能。

举例：

- 在 GitHub 上搜索代码

  ![image-20210720193623245](./assets/image-20210720193623245.png)

- 在电商网站上搜索商品

  ![image-20210720193633483](./assets/image-20210720193633483.png)

- 在谷歌上搜索答案

  ![image-20210720193641907](./assets/image-20210720193641907.png)

- 在打车软件上搜索附近的车

  ![image-20210720193648044](./assets/image-20210720193648044.png)

### ELK 技术栈

Elasticsearch 结合 Kibana、Logstash、Beats，也就是 Elastic Stack（ELK）。被广泛应用在日志数据分析、实时监控等领域。

![image-20210720194008781](./assets/image-20210720194008781.png)

Elasticsearch 是 Elastic Stack 的核心，负责存储、搜索、分析数据。

![image-20210720194230265](./assets/image-20210720194230265.png)

### Elasticsearch 和 Lucene

Elasticsearch 底层是基于 **Lucene** 来实现的。

**Lucene** 是一个 Java 语言的搜索引擎类库，是 Apache 公司的顶级项目，由 DougCutting（Hadoop 作者） 于1999年研发。官网地址：[https://lucene.apache.org/](https://lucene.apache.org/) 。

Lucene 的优势：

- 易扩展
- 高性能（基于倒排索引）

Lucene 的缺点：

- 只限于 Java 开发
- 学习曲线陡峭
- 不支持水平扩展

Elasticsearch 的发展历史：

- 2004 年 Shay Banon 基于 Lucene 开发了 Compass 给她老婆网上搜索食谱用
- 2010 年 Shay Banon 重写了 Compass，取名为 Elasticsearch 

Elasticsearch 官网地址：[https://www.elastic.co/cn/elasticsearch](https://www.elastic.co/cn/elasticsearch)，相比于 Lucene，Elasticsearch 具备以下优势： 

- 支持分布式，非常容易做到水平扩展
- 提供 Restful 接口，可被任何语言调用

### 为什么不是其他的搜索技术

DB ranking 网站上，全球搜索引擎技术排名：

![image-20210720195142535](./assets/image-20210720195142535.png)

1. Elasticsearch：开源的分布式搜索引擎
2. Splunk：商业项目
3. Solr：Apache 的开源搜索引擎

虽然在早期，Apache Solr 是最主要的搜索引擎技术，但随着时代发展，Elasticsearch 已经渐渐超越了 Solr：

![image-20210720195306484](./assets/image-20210720195306484.png)

## 倒排索引

倒排索引的概念是相对于 MySQL 这样的正向索引而言的。

### 正向索引

传统数据库（如 MySQL）采用正向索引，例如给下表（tb_goods）中的 id 创建索引：

| id   | title          | price |
| ---- | -------------- | ----- |
| 1    | 小米手机       | 3499  |
| 2    | 华为手机       | 4999  |
| 3    | 华为小米充电器 | 49    |
| 4    | 小米手环       | 49    |
| ……   | ……             | ……    |

如果根据 id 进行查询，那么直接走索引（比如 B+ 树），查询速度会非常快。

但如果是基于 title 做模糊查询，只能是逐行扫描数据，流程如下：

1. 用户搜索数据，条件是 title 符合 `"%手机%"`
2. 逐行获取数据，比如 id 为1的数据
3. 判断数据中的 title 是否符合用户搜索条件
4. 如果符合则放入结果集，不符合则丢弃且回到步骤 1

![image-20210720195531539](./assets/image-20210720195531539.png)

**逐行扫描，也就是全表扫描，随着数据量增加，其查询效率也会越来越低，当数据量达到百万级别时，就是一场灾难。**

### 倒排索引

倒排索引中有两个非常重要的概念：

- 文档（`Document`）：用来搜索的数据，其中的 **每一条数据就是一个文档**。例如一个网页、一个商品信息
- 词条（`Term`）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条

**创建倒排索引 **是对正向索引的一种特殊处理，流程如下：

- 将每一个文档的数据利用算法分词，得到一个个词条
- 创建表，每行数据包括词条、词条所在文档 id、位置等信息
- 因为词条唯一性，可以给词条创建索引，例如 hash 表结构索引

![image-20210720200457207](./assets/image-20210720200457207.png)

使用倒排索引的 **搜索流程** 如下（以搜索"华为手机"为例）：

1. 用户输入条件 `"华为手机"` 进行搜索
2. 对用户输入内容 **分词**，得到词条：`华为`、`手机`
3. 拿着词条在倒排索引中查找，可以得到包含词条的文档 id：1、2、3
4. 拿着文档 id 到正向索引中查找具体文档

![image-20210720201115192](./assets/image-20210720201115192.png)

虽然要先查询倒排索引，再查询正向索引，但是无论是词条、还是文档 id 都建立了索引，查询速度非常快，无需全表扫描。

### 正向和倒排

那么为什么一个叫做正向索引，一个叫做倒排索引呢？

- **正向索引** 是最传统的，根据 id 索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条。是 **根据文档找词条的过程**。

- 而 **倒排索引 **则相反，是先找到用户要搜索的词条，根据词条得到包含词条的文档的 id，然后根据 id 获取文档。是 **根据词条找文档的过程**。

### 优缺点比较

**正向索引**：

优点：
- 可以给多个字段创建索引
- 根据索引字段搜索、排序速度非常快

缺点：
- 根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描

**倒排索引**：

优点：
- 根据词条搜索、模糊搜索时，速度非常快

缺点：
- 只能给词条创建索引，而不是字段
- 无法根据字段做排序

## Elasticsearch 的一些概念

Elasticsearch 中有很多独有的概念，与 MySQL 中略有差别，但也有相似之处。

### 文档和字段

Elasticsearch 是面向 **文档（Document）**存储的，文档可以是数据库中的一条商品数据，一个订单信息。

文档数据会被序列化为 JSON 格式后存储在 Elasticsearch 中。

![image-20210720202707797](./assets/image-20210720202707797.png)

而 JSON 文档中往往包含很多的 **字段（Field）**，类似于数据库中的列。

### 索引和映射

**索引（Index）**，就是相同类型的文档的集合。

例如：

- 所有用户文档，就可以组织在一起，称为用户的索引；
- 所有商品的文档，可以组织在一起，称为商品的索引；
- 所有订单的文档，可以组织在一起，称为订单的索引；

![image-20210720203022172](./assets/image-20210720203022172.png)

因此，我们可以把索引当做是数据库中的表。

数据库的表会有约束信息，用来定义表的结构、字段的名称、类型等信息。因此，索引库中就有 **映射（mapping）**，是索引中文档的字段约束信息，类似表的结构约束。

### MySQL 与 Elasticsearch

MySQL 与 Elasticsearch 的概念对比：

| **MySQL** | **Elasticsearch** | **说明**                                                     |
| --------- | ----------------- | ------------------------------------------------------------ |
| Table     | Index             | 索引（index），就是文档的集合，类似数据库的表（table）       |
| Row       | Document          | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是 JSON 格式 |
| Column    | Field             | 字段（Field），就是 JSON 文档中的字段，类似数据库中的列（Column） |
| Schema    | Mapping           | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） |
| SQL       | DSL               | DSL 是 Elasticsearch 提供的 JSON 风格的请求语句，用来操作 Elasticsearch，实现 CRUD |

两者的擅长领域：

- MySQL：擅长事务类型操作，可以确保数据的安全和一致性

- Elasticsearch：擅长海量数据的搜索、分析、计算

因此在企业中往往是两者结合使用：

- 对安全性要求较高的 **写操作**，使用 MySQL 实现
- 对查询性能要求较高的 **搜索需求**，使用 Elasticsearch 实现
- 两者再基于某种方式，实现 **数据的同步**，保证一致性

![image-20210720203534945](./assets/image-20210720203534945.png)

### 分词器

作用场景：

- 在创建倒排索引时对文档进行分词
- 在用户搜索时，对输入的内容进行分词

IK 分词器的模式：

- ik_smart：智能切分，对文本做最粗粒度的拆分
- ik_max_word：最细切分，对文本做最细粒度的拆分

IK 分词器如何拓展词条，如何停用词条：

- 利用 config 目录的 `IkAnalyzer.cfg.xml` 文件添加拓展词典和停用词典
- 在词典中添加拓展词条或者停用词条

## 索引库操作

索引库就类似数据库表，mapping 映射就类似表的结构。

要向 ES 中存储数据，必须先创建“库”和“表”。

### mapping 映射属性

mapping 是对索引库中文档的约束，常见的 mapping 属性包括：

- type：字段数据类型，常见的简单类型有：
  - 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip 地址）
  - 数值：long、integer、short、byte、double、float、
  - 布尔：boolean
  - 日期：date
  - 对象：object
- index：是否创建索引，默认为 true
- analyzer：使用哪种分词器
- properties：该字段的子字段

例如下面的 JSON 文档：

```json
{
    "age": 21,
    "weight": 52.1,
    "isMarried": false,
    "info": "黑马程序员Java讲师",
    "email": "zy@itcast.cn",
    "score": [99.1, 99.5, 98.9],
    "name": {
        "firstName": "云",
        "lastName": "赵"
    }
}
```

对应的每个字段映射（mapping）：

- age：类型为 integer；参与搜索，因此需要 index 为 true；无需分词器
- weight：类型为 float；参与搜索，因此需要 index 为 true；无需分词器
- isMarried：类型为 boolean；参与搜索，因此需要 index 为 true；无需分词器
- info：类型为字符串，需要分词，因此是 text；参与搜索，因此需要 index 为 true；分词器可以用 ik_smart
- email：类型为字符串，但是不需要分词，因此是 keyword；不参与搜索，因此需要 index 为 false；无需分词器
- score：虽然是数组，但是我们只看元素的类型，类型为 float；参与搜索，因此需要 index 为 true；无需分词器
- name：类型为 object，需要定义多个子属性
  - name.firstName；类型为字符串，但是不需要分词，因此是 keyword；参与搜索，因此需要 index 为true；无需分词器
  - name.lastName；类型为字符串，但是不需要分词，因此是 keyword；参与搜索，因此需要 index 为true；无需分词器

### type 属性的变化

在 ES 的最新版本中，文档类型（`type`）的概念已经被逐渐弃用。在 ES 的早期版本中，一个索引可以包含多种类型的文档，这些类型用于表示索引中不同种类的数据集合。但是，从 6.x 版本开始，ES 团队决定逐步移除这种类型概念，原因包括：

1. **性能和复杂性**：多类型索引在内部实际上是在单个 Lucene 索引中共享，这导致了复杂的映射和存储管理，增加了性能负担。
2. **逻辑上的问题**：多类型索引意味着不同类型的文档共享同一个字段可能会有不同的数据类型，这违反了字段映射的一致性原则，可能导致数据不一致。
3. **简化API和用例**：移除类型概念有助于简化 API 的使用，使 ES 更加容易理解和使用，尤其是对于新用户。

重要的变化和版本

- **Elasticsearch 6.x**：引入了单类型索引的概念，即一个索引只能有一个类型。但是，它允许索引中存在名为 `_doc` 的类型，为全面移除类型概念做准备。
- **Elasticsearch 7.x**：类型参数在索引创建 API 中变成了可选项，而且默认情况下，文档的类型被命名为 `_doc`。在这个版本中，即使类型仍然在 URL 中可见，实际上它的作用已经大大减少。
- **Elasticsearch 8.x**：预计将完全移除文档类型的概念。

### 创建索引库

**基本语法**：

- 请求方式：PUT
- 请求路径：/索引库名，可以自定义
- 请求参数：mapping 映射

格式：

```json
PUT /{索引库名称}
{
  "mappings": {
    "properties": {
      "字段名":{
        "type": "text",
        "analyzer": "ik_smart"
      },
      "字段名2":{
        "type": "keyword",
        "index": "false"
      },
      "字段名3":{
        "properties": {
          "子字段": {
            "type": "keyword"
          }
        }
      },
      // ...略
    }
  }
}
```

### 查询索引库

**基本语法**：

- 请求方式：GET

- 请求路径：/索引库名

- 请求参数：无

**格式**：

```
GET /{索引库名称}
```

### 删除索引库

**语法：**

- 请求方式：DELETE

- 请求路径：/索引库名

- 请求参数：无

**格式：**

```
DELETE /{索引库名称}
```

### 修改索引库

ES 中的索引映射（mapping）是用来定义索引中字段的数据类型和其他属性的。在 ES 的设计中，**一旦一个字段的映射被创建，这个字段的映射就不能再被修改**。这是因为修改已有字段的映射可能会导致索引中已经存储的数据与新的映射不兼容，进而影响索引的整体一致性和查询的准确性。例如，如果一个字段最初被映射为一个整数类型，然后修改为字符串类型，那么已经存储为整数的数据就不能正确地被处理为字符串。

然而， **ES 允许向映射中添加新的字段**。这是因为添加新字段不会影响到已经存在的数据。新字段只会在新索引的文档或更新的文档中存在，而不会影响旧文档的结构。这种灵活性使得用户可以逐渐扩展他们的数据模型而无需重新索引现有数据。

如果需要修改已有字段的映射，通常的做法是创建一个新的索引，并在这个新索引中定义正确的映射。然后，可以将旧索引中的数据重新索引到新索引中。这种方法虽然成本较高，但可以确保数据的一致性和完整性得到维护。

**语法说明**：

```json
PUT /{索引库名称}/_mapping
{
  "properties": {
    "新字段名":{
      "type": "integer"
    }
  }
}
```

## 文档操作

### 新增文档

**语法：**

```json
POST /{索引库名称}/_doc/{文档id}
{
    "字段1": "值1",
    "字段2": "值2",
    "字段3": {
        "子属性1": "值3",
        "子属性2": "值4"
    },
    // ...
}
```

### 查询文档

根据 Restful 风格，新增是 post，查询应该是 get，不过查询一般都需要条件，这里我们把文档 id 带上。

这个请求是根据索引名称和文档的 ID 来精确查询的，返回的内容包括文档的详细信息，如果该文档存在的话。

**语法：**

```json
GET /{索引库名称}/_doc/{文档id}
```

如果文档存在，Elasticsearch 将返回包含以下信息的JSON对象：

- `_index`：返回文档所在的索引名称。
- `_type`：文档的类型（在最新版本的 Elasticsearch 中，默认为 `_doc`）。
- `_id`：查询的文档的ID。
- `_version`：文档的版本号，每次文档更新时，版本号会递增。
- `_source`：文档的源数据，即存储在索引中的原始数据。
- `_seq_no` 和 `_primary_term`：这些是内部版本控制字段，用于乐观并发控制。
- `found`：一个布尔值，指示是否找到文档。如果文档存在，此值为 `true`；如果不存在，则为 `false`。

### 删除文档

删除使用DELETE请求，同样，需要根据id进行删除：

**语法：**

```js
DELETE /{索引库名称}/_doc/{文档id}
```

### 修改文档

#### 全量修改

全量修改是覆盖原来的文档，其本质是：

- 根据指定的 id 删除文档
- 新增一个相同 id 的文档

**注意**：如果根据 id 删除时，id 不存在，第二步的新增也会执行，也就是说修改操作变成了新增操作。

**语法：**

```json
PUT /{索引库名}/_doc/{文档id}
{
    "字段1": "值1",
    "字段2": "值2",
    // ... 略
}
```

#### 增量修改

增量修改是只修改指定 id 匹配的文档中的部分字段。

**语法：**

```json
POST /{索引库名}/_update/{文档id}
{
    "doc": {
         "字段名": "新的值",
    }
}
```

## DSL 查询语法

### DSL 查询的分类

Elasticsearch 提供了基于 JSON 的 DSL（[Domain Specific Language](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)）来定义查询。常见的查询类型包括：

- **查询所有**：查询出所有数据，一般测试用。例如：`match_all`

- **全文检索（full text）查询**：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：
  - `match_query`
  - `multi_match_query`
- **精确查询**：根据精确词条值查找数据，一般是查找 keyword、数值、日期、boolean 等类型字段。例如：
  - `ids`
  - `range`
  - `term`
- **地理（geo）查询**：根据经纬度查询。例如：
  - `geo_distance`
  - `geo_bounding_box`
- **复合（compound）查询**：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：
  - `bool`
  - `function_score`

### DSL 查询的基本语法

查询的基本语法如下：

```json
GET /{索引库名称}/_search
{
  "query": {
    "查询类型": {
      "查询条件": "条件值"
    }
  }
}
```

我们以 **查询所有** 为例，其中：

- 查询类型为 `match_all`
- 没有查询条件

```json
// 查询所有
GET /{索引库名称}/_search
{
  "query": {
    "match_all": {
    }
  }
}
```

其它查询无非就是 **查询类型**、**查询条件** 的变化。

### 查询的常规返回值

从 Elasticsearch 进行查询时，返回的响应包含多个重要的字段，每个字段都有其特定的含义和用途：

`took`：表示 Elasticsearch 执行查询所花费的时间，单位是毫秒。用来帮助了解查询的性能，方便性能调优。

`timed_out`：布尔值，表示查询是否因为超时而没有完成。监控和警报系统中常用，用以检测可能的性能问题。

`_shards：`：包含关于查询涉及的分片的信息，包括总分片数、成功查询的分片数、失败的分片数等。用来诊断分布式查询中可能的问题，如某个分片的故障。

- `total`：查询涉及的分片总数。
- `successful`：成功返回结果的分片数。
- `skipped`：在查询过程中跳过的分片数（通常在使用分片路由或有缓存结果时出现）。
- `failed`：查询失败的分片数。

`hits`：包含实际的查询结果，是查询最重要的部分。展示查询结果，用于后续的数据处理或显示.

- `total`：匹配查询条件的文档总数。从 ES 7.x 开始，这个字段返回一个对象，包含 `value`（匹配数）和`relation`（表示是否精确）。
- `hits`：包含一个数组，每个元素代表一个匹配的文档。
  - `_index`：文档所在的索引名。
  - `_type`：文档的类型（在 ES 7.x 中基本废弃，所有文档类型默认为 `_doc`）。
  - `_id`：文档的 ID。
  - `_score`：文档的相关性得分，根据查询的 relevancy 计算得出。
  - `_source`：文档的原始数据（如果查询请求中指定返回）。

`aggregations`：如果查询中包含聚合操作，该字段包含聚合的结果。进行统计分析和数据汇总。

### 全文检索查询

全文检索查询的基本流程如下：

- 对用户搜索的内容做分词，得到词条
- 根据词条去倒排索引库中匹配，得到文档id
- 根据文档 id 找到文档，返回给用户

比较常用的场景包括：

- 商城的输入框搜索
- 百度输入框搜索

因为是拿着词条去匹配，因此参与搜索的字段也必须是可分词的 text 类型的字段。

#### 基本语法

常见的全文检索查询包括：

- `match` 查询：单字段查询
- `multi_match` 查询：多字段查询，任意一个字段符合条件就算符合查询条件

`match` 查询语法如下：

```json
GET /{索引库名称}/_search
{
  "query": {
    "match": {
      "{字段名称}": "TEXT"
    }
  }
}
```

`mulit_match` 语法如下：

```json
GET /{索引库名称}/_search
{
  "query": {
    "multi_match": {
      "query": "TEXT",
      "fields": ["FIELD1", " FIELD12"]
    }
  }
}
```

但是，参与查询的字段越多，对查询性能影响越大，因此建议采用 `copy_to`，然后单字段查询的方式。

### 精准查询

精确查询一般是查找 keyword、数值、日期、boolean 等类型字段。所以 **不会** 对搜索条件分词。常见的有：

- `term`：根据词条精确值查询
- `range`：根据值的范围查询

#### term 查询

因为精确查询的字段搜索的是不分词的字段，因此查询的条件也必须是 **不分词** 的词条。

查询时，用户输入的内容跟字段值完全匹配时才认为符合条件。

如果用户输入的内容是多个词语形成的短语，反而搜索不到数据。

语法说明：

```json
// term查询
GET /{索引库名称}/_search
{
  "query": {
    "term": {
      "FIELD": {
        "value": "VALUE"
      }
    }
  }
}
```

#### range 查询

范围查询，一般应用在对数值类型做范围过滤的时候。比如做价格范围过滤。

基本语法：

```json
// range查询
GET /{索引库名称}/_search
{
  "query": {
    "range": {
      "{字段名称}": {
        "gte": 10, // 这里的 gte 代表大于等于，gt 则代表大于
        "lte": 20 // lte 代表小于等于，lt 则代表小于
      }
    }
  }
}
```

### 地理坐标查询

所谓的地理坐标查询，其实就是根据经纬度查询，官方文档：[https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-queries.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-queries.html)

常见的使用场景包括：

- 携程：搜索我附近的酒店
- 滴滴：搜索我附近的出租车
- 微信：搜索我附近的人

#### 矩形范围查询

`geo_bounding_box`：查询 `geo_point` 落在某个矩形范围的所有文档。

查询时，需要指定矩形的 **左上**、**右下 **两个点的坐标，然后根据其生成的矩形，落在其中的都是符合条件的点。

![DKV9HZbVS6](./assets/DKV9HZbVS6-1717558758889-1.gif)

语法如下：

```json
// geo_bounding_box查询
GET /{索引库名称}/_search
{
  "query": {
    "geo_bounding_box": {
      "{字段名称}": {
        "top_left": { // 左上点
          "lat": 31.1,
          "lon": 121.5
        },
        "bottom_right": { // 右下点
          "lat": 30.9,
          "lon": 121.7
        }
      }
    }
  }
}
```

这种方式并不适合“附近的人”这样的圆形范围查询需求。

#### 附近查询（距离查询）

`geo_distance`：查询到指定中心点小于某个距离值的所有文档。

换句话来说，在地图上找一个点作为圆心，以指定距离为半径，画一个圆，落在圆内的坐标都算符合条件。

![vZrdKAh19C](./assets/vZrdKAh19C-1717559777113-3.gif)

语法如下：

```json
// geo_distance 查询
GET /{索引库名称}/_search
{
  "query": {
    "geo_distance": {
      "distance": "15km", // 半径
      "{字段名称}": "31.21,121.5" // 圆心
    }
  }
}
```

### 复合查询

复合（compound）查询：复合查询可以将其它简单查询组合起来，实现更复杂的搜索逻辑。常见的有两种：

- `fuction score`：算分函数查询，可以控制文档相关性算分，控制文档排名
- `bool query`：布尔查询，利用逻辑关系组合多个其它的查询，实现复杂搜索

#### 相关性算分

当我们利用 `match` 查询时，文档结果会根据与搜索词条的关联度打分（`_score`），返回结果时按照分值降序排列。

例如，我们搜索 "虹桥如家"，结果如下：

```json
[
  {
    "_score" : 17.850193,
    "_source" : {
      "name" : "虹桥如家酒店真不错",
    }
  },
  {
    "_score" : 12.259849,
    "_source" : {
      "name" : "外滩如家酒店真不错",
    }
  },
  {
    "_score" : 11.91091,
    "_source" : {
      "name" : "迪士尼如家酒店真不错",
    }
  }
]
```

在 Elasticsearch 5.x 之前，搜索的相关性打分主要依据 TF/IDF（词频/逆文档频率）模型。这个模型考虑了两个主要因素：

- **TF（Term Frequency）**：词频，即一个词在文档中出现的频率。词出现得越频繁，它对文档的重要性越高。
- **IDF（Inverse Document Frequency）**：逆文档频率，衡量一个词的普遍重要性。如果一个词在很少的文档中出现，则认为它具有很高的区分度，IDF 值较高。

公式如下：

![image-20210721190152134](./assets/image-20210721190152134-1717566719140-7.png)

从 Elasticsearch 5.x 版本开始，默认使用的打分算法是 BM25，这是一种更为现代的、基于概率的排名函数，用于替代传统的 TF/IDF 方法。BM25 被设计用来克服 TF/IDF 模型的一些限制，特别是在处理长文档或短查询时的性能问题。

BM25 的公式考虑了以下几个要素：

- **词频（TF）**：在 BM25 中，词频的影响经过了优化，以防一个词在文档中大量出现时对整体打分的影响过大。
- **文档频率（DF）**：类似于 IDF，但在 BM25 中使用的是文档频率的逆向非线性函数。
- **文档长度**：BM25 还考虑了文档长度的因素，对长文档和短文档进行了归一化处理，以避免长文档仅因为单词总数多而获得过高的评分。

公式如下：

![image-20210721190416214](./assets/image-20210721190416214-1717566743773-9.png)

TF/IDF 算法有一各缺陷，就是词条频率越高，文档得分也会越高，单个词条对文档影响较大。

而 BM25 则会让单个词条的算分有一个上限，曲线更加平滑：

![image-20210721190907320](./assets/image-20210721190907320-1717566711042-5.png)

#### Function Score Query

根据相关度打分是一种比较合理的算分方式，但 **合理的不一定是产品经理需要** 的。

以百度搜索为例，并不是相关度越高排名越靠前，而是谁掏的钱多排名就越靠前。

要想更精细地控制搜索结果的排名，就需要利用 Elasticsearch 中的 **Function Score Query** 了，它是一种非常强大的查询，可以根据多种函数来修改或增强查询结果的相关性得分。

使用这种查询，我们可以在查询结果的排序中加入自定义的逻辑，例如基于某些字段的数值、随机化处理、地理位置信息等来调整得分。

语法说明：

![image-20210721191544750](./assets/image-20210721191544750-1717568733268-11.png)

function score 查询中包含四部分内容：

- **原始查询条件**：query 部分，基于这个条件搜索文档，并且基于 BM25 算法给文档打出 **原始算分**（query score)
- **过滤条件**：filter 部分，符合该条件的文档才会 **重新算分**
- **算分函数**：符合 filter 条件的文档要根据这个函数做运算，得到的 **函数算分**（function score），有四种函数
  - weight：函数结果是常量
  - field_value_factor：以文档中的某个字段值作为函数结果
  - random_score：以随机数作为函数结果
  - script_score：自定义算分函数
- **运算模式**：算分函数的结果、原始查询的相关性算分，两者之间的运算方式，包括：
  - multiply：相乘
  - replace：用 function score 替换 query score
  - 其它，例如：sum、avg、max、min

function score 的运行流程如下：

1. 根据 **原始查询条件 **查询搜索文档，并且计算相关性算分，称为 **原始算分**（query score）
2. 根据 **过滤条件**，过滤文档
3. 符合 **过滤条件** 的文档，基于 **算分函数** 运算，得到 **函数算分**（function score）
4. 将 **原始算分** （query score）和 **函数算分**（function score）基于 **运算模式** 做运算，得到最终结果，作为相关性算分

因此，其中的关键点是：

- 过滤条件：决定哪些文档的算分被修改
- 算分函数：决定函数算分的算法
- 运算模式：决定最终算分结果

#### Boolean Query

**Boolean Query** 是一种复杂的查询类型，它允许我们结合多个查询条件，通过逻辑操作符（如 AND、OR、NOT）来构建更复杂的查询逻辑。这种查询在实际应用中非常常见，尤其是当我们需要在搜索中包含多个条件或排除某些文档时。

Boolean Query 主要由以下四个部分组成：

1. **must**：查询中的这部分条件必须满足（逻辑 AND）。如果添加多个查询到 `must` 部分，返回的文档必须满足所有这些条件，**`must` 会参与算分**。
2. **should**：查询中的这部分条件至少满足一个（逻辑 OR）。`should` 查询可以用于 **增加那些匹配的文档的相关性得分**，使其在结果列表中排名更高。如果 `should` 查询是 `boolean` 查询中唯一的条件，那么至少需要匹配一个 `should` 条件，但如果 `boolean` 查询中也包含了 `must` 或 `filter`，则 `should` 可以不匹配也可以返回结果。
3. **must_not**：查询中的这部分条件必须不满足（逻辑 NOT）。它用于排除包含特定条件的文档。
4. **filter**：这与 `must` 类似，查询中的这部分条件必须满足，但是与 `must` 不同的是，**`filter` 不会影响得分，仅用于过滤文档**。这使得 `filter` 在性能上通常比 `must` 更优，特别是当你只是想过滤数据而不关心得分时。

比如在搜索酒店时，除了关键字搜索外，我们还可能根据品牌、价格、城市等字段做过滤。

每一个不同的字段，其查询的条件、方式都不一样，必须是多个不同的查询，而要组合这些查询，就必须用 bool 查询了。

需要注意的是，搜索时 **参与打分的字段越多，查询的性能越差**。

因此，这种多条件查询时建议：

- 搜索框的关键字搜索，是全文检索查询，使用 must 查询，参与算分
- 其它过滤条件，采用 filter 查询。不参与算分

语法示例：

```json
GET /hotel/_search
{
  "query": {
    "bool": {
      "must": [
        { "term": {"city": "上海" }}
      ],
      "should": [
        { "term": {"brand": "皇冠假日" }},
        { "term": {"brand": "华美达" }}
      ],
      "must_not": [
        { "range": { "price": { "lte": 500 } }}
      ],
      "filter": [
        { "range": {"score": { "gte": 45 } }}
      ]
    }
  }
}
```

## 搜索结果处理

### 排序

Elasticsearch 默认是根据相关度算分（`_score`）来排序，但是也支持自定义方式对搜索[结果排序](https://www.elastic.co/guide/en/elasticsearch/reference/current/sort-search-results.html)。可以排序字段类型有：keyword 类型、数值类型、地理坐标类型、日期类型等。

#### 普通字段排序

keyword、数值、日期类型排序的语法基本一致。

**语法**：

```json
GET /{索引库名称}/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "{排序字段}": "desc"  // 排序字段、排序方式 ASC、DESC
    }
  ]
}
```

排序条件是一个数组，也就是可以写多个排序条件。

按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推。

#### 地理坐标排序

地理坐标排序略有不同。

**语法说明**：

```json
GET /{索引库名称}/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "_geo_distance" : {
          "{排序字段}" : "纬度，经度", // 文档中 geo_point 类型的字段名、目标坐标点
          "order" : "asc", // 排序方式
          "unit" : "km" // 排序的距离单位
      }
    }
  ]
}
```

这个查询的含义是：

- 指定一个坐标，作为目标点
- 计算每一个文档中，指定字段（必须是 geo_point 类型）的坐标到目标点的距离是多少
- 根据距离排序

### 分页

Elasticsearch 默认情况下只返回 top10 的数据。而如果要查询更多数据就需要修改分页参数了。

Elasticsearch 中通过修改 from、size 参数来控制要返回的分页结果：

- from：从第几个文档开始
- size：总共查询几个文档

类似于 MySQL 中的 `limit ?, ?`

#### 基本的分页

分页的基本语法如下：

```json
GET /{索引库名称}/_search
{
  "query": {
    "match_all": {}
  },
  "from": 0, // 分页开始的位置，默认为0
  "size": 10, // 期望获取的文档总数
  "sort": [
    {"price": "asc"}
  ]
}
```

#### 深度分页问题

现在，我要查询 990~1000 的数据，查询逻辑要这么写：

```json
GET /{索引库名称}/_search
{
  "query": {
    "match_all": {}
  },
  "from": 990, // 分页开始的位置，默认为0
  "size": 10, // 期望获取的文档总数
  "sort": [
    {"price": "asc"}
  ]
}
```

不过，Elasticsearch 内部分页时，必须先查询第 0~1000 条，然后截取其中的 990~1000 的这 10 条。

这导致但这种方法在处理非常大的数据集时可能会遇到性能问题。随着 `from` 值的增大，查询的成本也增大，尤其是在高 `from` 值时，Elasticsearch 需要处理和跳过更多的结果。

在 Elasticsearch 的单节点部署中，查询 TOP1000 数据通常不会造成太大的性能问题。

然而，在面对集群部署时，情况则变得复杂许多。

假设 Elasticsearch 集群由 5 个节点组成，单纯地从每个节点查询 TOP200 并不能保证得到整个集群的 TOP1000 数据。

因为某个节点的 TOP200 数据，在集群中的整体排名可能远低于10000 名。

要准确获得集群范围内的 TOP1000 数据，必须从每个节点提取 TOP1000 的结果，然后对这些数据进行汇总和重新排名，最后才能截取出真正的 TOP1000。

那么，如果需要查询第 9900 到 10000 名的数据怎么办？这可能需要在每个节点上查询前 10000 名的数据，再**将所有节点的数据汇总到内存中进行排序和筛选**，这是一个资源消耗极大的操作。

当查询涉及到较深的分页时，如尝试检索非常靠后的数据，会对内存和 CPU 造成重大压力。为了防止这种情况，Elasticsearch 默认禁止执行 `from + size` 超过 10000 的请求，以避免过大的性能开销。

针对深度分页，ES 提供了三种解决方案，[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html)：

- **Scroll API**：原理将排序后的文档 id 形成快照，保存在内存。官方已经不推荐使用。
- **Search After**：分页时需要排序，原理是以上一次查询结果中最后一条记录的排序值，以此作为下一次查询的起点。官方推荐使用的方式。
- **Point In Time (PIT) API**：这是 Elasticsearch 7.10 引入的新特性，用于提供像 Scroll 那样的稳定视图，但与 Search After 结合使用，以支持更有效的分页。

#### 分页查询的常见实现方案以及优缺点：

- `from + size`：
  - 优点：支持随机翻页
  - 缺点：深度分页问题，默认查询上限（from + size）是10000
  - 场景：百度、京东、谷歌、淘宝这样的随机翻页搜索
- `after search`：
  - 优点：没有查询上限（单次查询的 size 不超过10000）
  - 缺点：只能向后逐页查询，不支持随机翻页
  - 场景：没有随机翻页需求的搜索，例如手机向下滚动翻页

- `scroll`：
  - 优点：没有查询上限（单次查询的 size 不超过10000）
  - 缺点：会有额外内存消耗，并且搜索结果是非实时的
  - 场景：海量数据的获取和迁移。从 ES7.1 开始不推荐，建议用 after search 方案。

### 高亮

我们在百度，京东搜索时，关键字会变成红色，比较醒目，这叫高亮显示。

高亮显示的实现分为两步：

1. 给文档中的所有关键字都添加一个标签，例如 `<em>` 标签
2. 页面给 `<em>` 标签编写 CSS 样式

语法如下：

```json
GET /{索引库名称}/_search
{
  "query": {
    "match": {
      "{字段名称}": "TEXT" // 查询条件，高亮一定要使用全文检索查询
    }
  },
  "highlight": {
    "fields": { // 指定要高亮的字段
      "{字段名称}": {
        "pre_tags": "<em>",  // 用来标记高亮字段的前置标签
        "post_tags": "</em>" // 用来标记高亮字段的后置标签
      }
    }
  }
}
```

**注意**：

- 高亮是对关键字高亮，因此 **搜索条件必须带有关键字**，而不能是范围查询
- 默认情况下，**高亮的字段，必须与搜索指定的字段一致**，否则无法高亮
- 如果要对 **非搜索指定的字段** 高亮，则需要添加一个属性：`"required_field_match"： "false"`











